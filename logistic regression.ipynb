{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4912d41-945f-4afc-93c1-3a5e199ee1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Number of reviews: 10673\n",
      "âœ… Sample reviews:\n",
      " 0    too shity it is incredible that this fucking s...\n",
      "1    w game but bad on steam version nonsteam bette...\n",
      "2    why is this game so boring there are no bots i...\n",
      "3    games peace is too slow and weapons are too in...\n",
      "5    the game is great but standstill crouching wit...\n",
      "Name: cleaned_review, dtype: object\n",
      "âœ… Shape of X_train: (8538, 5000)\n",
      "âœ… Shape of X_test: (2135, 5000)\n",
      "\n",
      "ðŸ”¹ Logistic Regression Accuracy: 0.8969555035128806\n",
      "\n",
      "ðŸ”¹ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.33      0.47       295\n",
      "           1       0.90      0.99      0.94      1840\n",
      "\n",
      "    accuracy                           0.90      2135\n",
      "   macro avg       0.86      0.66      0.71      2135\n",
      "weighted avg       0.89      0.90      0.88      2135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Step 1: Import Libraries\n",
    "# ----------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Load Dataset\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"dataset1.csv\")\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Text Preprocessing\n",
    "# ----------------------------\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, float):  # Handle NaN/float values\n",
    "        text = \"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    words = word_tokenize(text)  # Tokenization\n",
    "    return \" \".join(words)  # Reconstruct text\n",
    "\n",
    "# Apply preprocessing\n",
    "df[\"cleaned_review\"] = df[\"review\"].fillna(\"\").apply(preprocess_text)\n",
    "\n",
    "# Drop empty rows after cleaning\n",
    "df = df[df[\"cleaned_review\"].str.strip() != \"\"]\n",
    "\n",
    "# Debug: Check dataset\n",
    "print(\"âœ… Number of reviews:\", len(df))\n",
    "print(\"âœ… Sample reviews:\\n\", df[\"cleaned_review\"].head())\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Prepare Labels\n",
    "# ----------------------------\n",
    "df[\"sentiment\"] = df[\"sentiment\"].str.strip()\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map({\"Positive\": 1, \"Negative\": 0})\n",
    "df = df.dropna(subset=['sentiment'])\n",
    "\n",
    "# Final inputs and outputs\n",
    "X = df[\"cleaned_review\"]\n",
    "y = df[\"sentiment\"].astype(int)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 5: Split Data\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 6: TF-IDF Vectorization\n",
    "# ----------------------------\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"âœ… Shape of X_train:\", X_train_tfidf.shape)\n",
    "print(\"âœ… Shape of X_test:\", X_test_tfidf.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 7: Train Logistic Regression\n",
    "# ----------------------------\n",
    "log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 8: Evaluate Model\n",
    "# ----------------------------\n",
    "y_pred = log_reg_model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nðŸ”¹ Logistic Regression Accuracy:\", accuracy)\n",
    "print(\"\\nðŸ”¹ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc82f5-20bc-4a1e-abca-4d7db763bc38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
