{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d394c81b-6e1b-4552-9dcd-a60491867bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 10673\n",
      "Sample reviews: 0    too shity it is incredible that this fucking s...\n",
      "1    w game but bad on steam version nonsteam bette...\n",
      "2    why is this game so boring there are no bots i...\n",
      "3    games peace is too slow and weapons are too in...\n",
      "5    the game is great but standstill crouching wit...\n",
      "Name: cleaned_review, dtype: object\n",
      "Dataset size after cleaning: (10673, 4)\n",
      "Sample cleaned reviews:\n",
      " 0    too shity it is incredible that this fucking s...\n",
      "1    w game but bad on steam version nonsteam bette...\n",
      "2    why is this game so boring there are no bots i...\n",
      "3    games peace is too slow and weapons are too in...\n",
      "5    the game is great but standstill crouching wit...\n",
      "Name: cleaned_review, dtype: object\n",
      "Preprocessing complete!\n",
      "[0 1]\n",
      "Shape of X_train: (8538, 5000)\n",
      "Shape of X_test: (2135, 5000)\n",
      "Length of y_train: 8538\n",
      "Length of y_test: 2135\n",
      "\n",
      "ðŸ”¹ Naive Bayes Model Accuracy: 0.8702576112412178\n",
      "\n",
      "ðŸ”¹ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.06      0.12       295\n",
      "           1       0.87      1.00      0.93      1840\n",
      "\n",
      "    accuracy                           0.87      2135\n",
      "   macro avg       0.91      0.53      0.53      2135\n",
      "weighted avg       0.88      0.87      0.82      2135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"dataset1.csv\")\n",
    "\n",
    "# Step 1: Preprocess Text Data\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, float):  # Handle NaN/float values\n",
    "        text = \"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    words = word_tokenize(text)  # Tokenization\n",
    "    return \" \".join(words)  # Reconstruct text\n",
    "\n",
    "# Apply preprocessing to dataset\n",
    "df[\"cleaned_review\"] = df[\"review\"].fillna(\"\").apply(preprocess_text)\n",
    "\n",
    "# Remove rows with empty cleaned reviews\n",
    "df = df[df[\"cleaned_review\"].str.strip() != \"\"]\n",
    "\n",
    "print(\"Number of reviews:\", len(df))  # Should be greater than 0\n",
    "print(\"Sample reviews:\", df[\"cleaned_review\"].head(5))  # Check sample text\n",
    "\n",
    "# Debugging checks\n",
    "print(\"Dataset size after cleaning:\", df.shape)\n",
    "print(\"Sample cleaned reviews:\\n\", df[\"cleaned_review\"].head())\n",
    "\n",
    "# Strip any extra spaces that might be causing issues with mapping\n",
    "df[\"sentiment\"] = df[\"sentiment\"].str.strip()\n",
    "\n",
    "# Save preprocessed data\n",
    "df.to_csv(\"preprocessed_dataset1.csv\", index=False)\n",
    "print(\"Preprocessing complete!\")\n",
    "\n",
    "# Step 2: Convert Sentiment Labels to Numeric\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map({\"Positive\": 1, \"Negative\": 0})\n",
    "\n",
    "# Check the unique values again\n",
    "print(df[\"sentiment\"].unique())\n",
    "\n",
    "df = df.dropna(subset=['sentiment'])\n",
    "\n",
    "# Convert labels to integer\n",
    "y = df[\"sentiment\"].astype(int)\n",
    "X = df[\"cleaned_review\"]\n",
    "\n",
    "# Step 3: Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit features to avoid sparse matrix issues\n",
    "X_train = vectorizer.fit_transform(X_train)  \n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Debugging checks\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Length of y_train:\", len(y_train))\n",
    "print(\"Length of y_test:\", len(y_test))\n",
    "\n",
    "# âœ… Step 5: Train Naive Bayes Classifier\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate Model\n",
    "y_pred = nb_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nðŸ”¹ Naive Bayes Model Accuracy:\", accuracy)\n",
    "print(\"\\nðŸ”¹ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbdf8b1-e4ed-479d-9e07-0ec6781236ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
