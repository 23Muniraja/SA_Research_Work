{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d560675d-72f0-4345-9ab5-81ebe3b405c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9575dd-35b9-45a4-b2d4-4264fb99ea49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\CHRISTIN\n",
      "[nltk_data]     SANTHOSH\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ba525b2-584b-48ac-948d-ddfa6b4e4cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 10673\n",
      "Sample reviews: 0    too shity it is incredible that this fucking s...\n",
      "1    w game but bad on steam version nonsteam bette...\n",
      "2    why is this game so boring there are no bots i...\n",
      "3    games peace is too slow and weapons are too in...\n",
      "5    the game is great but standstill crouching wit...\n",
      "Name: cleaned_review, dtype: object\n",
      "Dataset size after cleaning: (10673, 4)\n",
      "Sample cleaned reviews:\n",
      " 0    too shity it is incredible that this fucking s...\n",
      "1    w game but bad on steam version nonsteam bette...\n",
      "2    why is this game so boring there are no bots i...\n",
      "3    games peace is too slow and weapons are too in...\n",
      "5    the game is great but standstill crouching wit...\n",
      "Name: cleaned_review, dtype: object\n",
      "Preprocessing complete!\n",
      "[0 1]\n",
      "Shape of X_train: (8538, 5000)\n",
      "Shape of X_test: (2135, 5000)\n",
      "Length of y_train: 8538\n",
      "Length of y_test: 2135\n",
      "\n",
      "ðŸ”¹ Model Accuracy: 0.8730679156908665\n",
      "\n",
      "ðŸ”¹ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.16      0.26       295\n",
      "           1       0.88      0.99      0.93      1840\n",
      "\n",
      "    accuracy                           0.87      2135\n",
      "   macro avg       0.78      0.57      0.59      2135\n",
      "weighted avg       0.85      0.87      0.84      2135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"dataset1.csv\")\n",
    "\n",
    "# Step 1: Preprocess Text Data\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, float):  # Handle NaN/float values\n",
    "        text = \"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    words = word_tokenize(text)  # Tokenization\n",
    "    return \" \".join(words)  # Reconstruct text\n",
    "\n",
    "# Apply preprocessing to dataset\n",
    "df[\"cleaned_review\"] = df[\"review\"].fillna(\"\").apply(preprocess_text)\n",
    "\n",
    "# Remove rows with empty cleaned reviews\n",
    "df = df[df[\"cleaned_review\"].str.strip() != \"\"]\n",
    "\n",
    "print(\"Number of reviews:\", len(df))  # Should be greater than 0\n",
    "print(\"Sample reviews:\", df[\"cleaned_review\"].head(5))  # Check sample text\n",
    "\n",
    "# Debugging checks\n",
    "print(\"Dataset size after cleaning:\", df.shape)\n",
    "print(\"Sample cleaned reviews:\\n\", df[\"cleaned_review\"].head())\n",
    "\n",
    "# Strip any extra spaces that might be causing issues with mapping\n",
    "df[\"sentiment\"] = df[\"sentiment\"].str.strip()\n",
    "\n",
    "# Save preprocessed data\n",
    "df.to_csv(\"preprocessed_dataset1.csv\", index=False)\n",
    "print(\"Preprocessing complete!\")\n",
    "\n",
    "# Step 2: Convert Sentiment Labels to Numeric\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map({\"Positive\": 1, \"Negative\": 0})\n",
    "\n",
    "# Check the unique values again\n",
    "print(df[\"sentiment\"].unique())\n",
    "\n",
    "# Drop missing sentiment values if any\n",
    "df = df.dropna(subset=['sentiment'])\n",
    "\n",
    "# Convert labels to integer\n",
    "y = df[\"sentiment\"].astype(int)\n",
    "X = df[\"cleaned_review\"]\n",
    "\n",
    "# Step 3: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(X_train)  \n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Debugging checks\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Length of y_train:\", len(y_train))\n",
    "print(\"Length of y_test:\", len(y_test))\n",
    "\n",
    "# Step 5: Train K-Nearest Neighbors Classifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # You can tune n_neighbors\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate Model\n",
    "y_pred = knn_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nðŸ”¹ Model Accuracy:\", accuracy)\n",
    "print(\"\\nðŸ”¹ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c35dac-6014-4621-a5f0-abf099b8d538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
