{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "999a8bad-db9a-43df-b242-962853d55eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 10673\n",
      "Sample reviews: 0    too shity it is incredible that this fucking s...\n",
      "1    w game but bad on steam version nonsteam bette...\n",
      "2    why is this game so boring there are no bots i...\n",
      "3    games peace is too slow and weapons are too in...\n",
      "5    the game is great but standstill crouching wit...\n",
      "Name: cleaned_review, dtype: object\n",
      "Dataset size after cleaning: (10673, 4)\n",
      "Shape of X_train: (8538, 5000)\n",
      "Shape of X_test: (2135, 5000)\n",
      "Length of y_train: 8538\n",
      "Length of y_test: 2135\n",
      "\n",
      "ðŸ”¹ Model Accuracy: 0.8796252927400469\n",
      "\n",
      "ðŸ”¹ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.36      0.45       295\n",
      "           1       0.90      0.96      0.93      1840\n",
      "\n",
      "    accuracy                           0.88      2135\n",
      "   macro avg       0.76      0.66      0.69      2135\n",
      "weighted avg       0.86      0.88      0.87      2135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Import Libraries\n",
    "# ----------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ----------------------------\n",
    "# Load Dataset\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"dataset1.csv\")\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1: Preprocess Text Data\n",
    "# ----------------------------\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, float):  # Handle NaN/float values\n",
    "        text = \"\"\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
    "    words = word_tokenize(text)  # Tokenization\n",
    "    return \" \".join(words)  # Reconstruct text\n",
    "\n",
    "df[\"cleaned_review\"] = df[\"review\"].fillna(\"\").apply(preprocess_text)\n",
    "\n",
    "# Fix typo: 'claned_review' â†’ 'cleaned_review'\n",
    "df = df[df[\"cleaned_review\"].str.strip() != \"\"]\n",
    "\n",
    "print(\"Number of reviews:\", len(df))\n",
    "print(\"Sample reviews:\", df[\"cleaned_review\"].head(5))\n",
    "print(\"Dataset size after cleaning:\", df.shape)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Prepare Labels\n",
    "# ----------------------------\n",
    "df[\"sentiment\"] = df[\"sentiment\"].str.strip()\n",
    "df[\"sentiment\"] = df[\"sentiment\"].map({\"Positive\": 1, \"Negative\": 0})\n",
    "df = df.dropna(subset=['sentiment'])\n",
    "y = df[\"sentiment\"].astype(int)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Train/Test Split\n",
    "# ----------------------------\n",
    "X = df[\"cleaned_review\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: TF-IDF Vectorization\n",
    "# ----------------------------\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Length of y_train:\", len(y_train))\n",
    "print(\"Length of y_test:\", len(y_test))\n",
    "\n",
    "# ----------------------------\n",
    "# Step 5: Train Decision Tree Classifier\n",
    "# ----------------------------\n",
    "dt_model = DecisionTreeClassifier(max_depth=20, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 6: Evaluate Model\n",
    "# ----------------------------\n",
    "y_pred = dt_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"\\nðŸ”¹ Model Accuracy:\", accuracy)\n",
    "print(\"\\nðŸ”¹ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661a5d69-7dcd-480b-ab62-9eaa1a5d3afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
